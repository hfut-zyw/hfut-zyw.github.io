<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>第4章（下）：基于前馈神经网络完成鸢尾花分类任务 | Homepage | 张有为</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="4.5 实践：基于前馈神经网络完成鸢尾花分类在本实践中，我们继续使用第三章中的鸢尾花分类任务，将Softmax分类器替换为本章介绍的前馈神经网络。在本实验中，我们使用的损失函数为交叉熵损失；优化器为随机梯度下降法；评价指标为准确率。">
<meta property="og:type" content="article">
<meta property="og:title" content="第4章（下）：基于前馈神经网络完成鸢尾花分类任务">
<meta property="og:url" content="http://example.com/2022/08/12/nndl/chapter4B/index.html">
<meta property="og:site_name" content="Homepage | 张有为">
<meta property="og:description" content="4.5 实践：基于前馈神经网络完成鸢尾花分类在本实践中，我们继续使用第三章中的鸢尾花分类任务，将Softmax分类器替换为本章介绍的前馈神经网络。在本实验中，我们使用的损失函数为交叉熵损失；优化器为随机梯度下降法；评价指标为准确率。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ai-studio-static-online.cdn.bcebos.com/49287f7b41234d718fcc79b3f8edc64f366b05f460fb49cea88805777d508d82">
<meta property="og:image" content="https://ai-studio-static-online.cdn.bcebos.com/337735d2bf6c49dda5415d791f6a320ffe739a809b3541faa26bfb8331506cb3">
<meta property="og:image" content="http://example.com/img-nndl/output_19_0.png">
<meta property="article:published_time" content="2022-08-12T01:27:22.000Z">
<meta property="article:modified_time" content="2022-09-22T13:03:49.665Z">
<meta property="article:author" content="LabmemNo.001">
<meta property="article:tag" content="nndl案例与实践">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ai-studio-static-online.cdn.bcebos.com/49287f7b41234d718fcc79b3f8edc64f366b05f460fb49cea88805777d508d82">
  
    <link rel="alternative" href="/atom.xml" title="Homepage | 张有为" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/icon.gif">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  

  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

  
<script src="https://priesttomb.github.io/js/md5.min.js"></script>

  
<script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>

  
<script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>

  
<meta name="generator" content="Hexo 6.2.0"></head>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/img/face.png" class="js-avatar show" style="width: 100%;height: 100%;opacity: 1;">
		</a>

		<hgroup>
			<h1 class="header-author"><a href="/">LabmemNo.001</a></h1>
		</hgroup>

		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">

					<nav class="header-menu">
						<ul>
						
							<li><a href="/2022/08/09/me/aboutme">个人简介</a>
							</li>
				        
							<li><a href="/categories/notes">一些随写</a>
							</li>
				        
							<li><a href="/categories/analysis">抽象分析基础</a>
							</li>
				        
							<li><a href="/categories/probability">高等概率统计</a>
							</li>
				        
							<li><a href="/categories/opt">矩阵论与最优化</a>
							</li>
				        
						</ul>
					</nav>

					<nav class="header-menu">
						<ul>
						<li><a style="color:rgb(228, 117, 238)">Deep Learning </a>
							<nav class="header-submenu">
								<ul>
									
										<li><a href="/categories/pytorch"><div>Pytorch</div></a></li>  
									
										<li><a href="/categories/pydata"><div>数据处理</div></a></li>  
									
										<li><a href="/categories/nndl"><div>nndl案例与实践</div></a></li>  
									
								</ul>
							</nav>	
						</li>     
						</ul>
					</nav>
					
								
					


					<nav class="half-header-menu">
						<a class="hide">Home</a>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/hfut-zyw" title="github">github</a>
					        
								<a class="mail" target="_blank" href="mailto:lucario@qq.com" title="mail">mail</a>
					        
						</div>
						<!-- music -->
						
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Matplotlib%E7%AC%94%E8%AE%B0/" style="font-size: 10px;">Matplotlib笔记</a> <a href="/tags/Pandas%E7%AC%94%E8%AE%B0/" style="font-size: 18px;">Pandas笔记</a> <a href="/tags/Pytorch%E7%AC%94%E8%AE%B0/" style="font-size: 12px;">Pytorch笔记</a> <a href="/tags/nndl%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/" style="font-size: 20px;">nndl案例与实践</a> <a href="/tags/%E4%BC%98%E5%8C%96%E7%AC%94%E8%AE%B0/" style="font-size: 14px;">优化笔记</a> <a href="/tags/%E5%85%B3%E4%BA%8E%E6%88%91/" style="font-size: 10px;">关于我</a> <a href="/tags/%E5%88%86%E6%9E%90%E7%AC%94%E8%AE%B0/" style="font-size: 16px;">分析笔记</a> <a href="/tags/%E9%9A%8F%E5%86%99/" style="font-size: 14px;">随写</a>
					</div>
				</section>
				
				
				

				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
	<div class="overlay">
		<div class="slider-trigger"></div>
		<h1 class="header-author js-mobile-header hide"></h1>
	</div>
  <div class="intrude-less">
	  <header id="header" class="inner">
		  <div class="profilepic">
			  <img src="/img/face4.png" class="js-avatar show" style="width: 100%;height: 100%;opacity: 1;">
		  </div>
		  <hgroup>
			<h1 class="header-author"></h1>
		  </hgroup>
		  

		  <nav class="header-menu">
			  <ul>
			  
				  <li><a href="/2022/08/09/me/aboutme" style="color:rgba(69, 7, 241, 0.904)" >个人简介</a></li>
			  
				  <li><a href="/categories/notes" style="color:rgba(69, 7, 241, 0.904)" >一些随写</a></li>
			  
				  <li><a href="/categories/analysis" style="color:rgba(69, 7, 241, 0.904)" >抽象分析基础</a></li>
			  
				  <li><a href="/categories/probability" style="color:rgba(69, 7, 241, 0.904)" >高等概率统计</a></li>
			  
				  <li><a href="/categories/opt" style="color:rgba(69, 7, 241, 0.904)" >矩阵论与最优化</a></li>
			  
			  <div class="clearfix"></div>
			  </ul>
		  </nav>

		  <nav class="header-menu">
			  <ul>
			  <li><a style="color:rgba(69, 7, 241, 0.904)">Deep Learning </a>
				  <nav class="header-submenu">
					  <ul>
						  
							  <li><a href="/categories/pytorch" style="color:rgba(69, 7, 241, 0.904)" ><div>Pytorch</div></a></li>  
						  
							  <li><a href="/categories/pydata" style="color:rgba(69, 7, 241, 0.904)" ><div>数据处理</div></a></li>  
						  
							  <li><a href="/categories/nndl" style="color:rgba(69, 7, 241, 0.904)" ><div>nndl案例与实践</div></a></li>  
						  
					  </ul>
				  </nav>	
			  </li>     
			  </ul>
		  </nav>

		  <nav class="header-nav">
			  <div class="social">
				  
					  <a class="github" target="_blank" href="https://github.com/hfut-zyw" title="github">github</a>
				  
					  <a class="mail" target="_blank" href="mailto:lucario@qq.com" title="mail">mail</a>
				  
			  </div>
		  </nav>
	  </header>				
  </div>
</nav>
      <div class="body-wrap">

<article id="post-nndl/chapter4B" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/08/12/nndl/chapter4B/" class="article-date">
  	<time datetime="2022-08-12T01:27:22.000Z" itemprop="datePublished">2022-08-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      第4章（下）：基于前馈神经网络完成鸢尾花分类任务
      
          <span class="title-pop-out"></a>
      
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/nndl%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/" rel="tag">nndl案例与实践</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/nndl/">nndl</a>
	</div>


        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="4-5-实践：基于前馈神经网络完成鸢尾花分类"><a href="#4-5-实践：基于前馈神经网络完成鸢尾花分类" class="headerlink" title="4.5 实践：基于前馈神经网络完成鸢尾花分类"></a>4.5 实践：基于前馈神经网络完成鸢尾花分类</h2><p>在本实践中，我们继续使用第三章中的鸢尾花分类任务，将Softmax分类器替换为本章介绍的前馈神经网络。<br>在本实验中，我们使用的损失函数为交叉熵损失；优化器为随机梯度下降法；评价指标为准确率。</p>
<span id="more"></span>
<h3 id="4-5-1-小批量梯度下降法"><a href="#4-5-1-小批量梯度下降法" class="headerlink" title="4.5.1 小批量梯度下降法"></a>4.5.1 小批量梯度下降法</h3><p>在梯度下降法中，目标函数是整个训练集上的风险函数，这种方式称为<strong>批量梯度下降法（Batch Gradient Descent，BGD）</strong>。 批量梯度下降法在每次迭代时需要计算每个样本上损失函数的梯度并求和。当训练集中的样本数量$N$很大时，空间复杂度比较高，每次迭代的计算开销也很大。</p>
<p>为了减少每次迭代的计算复杂度，我们可以在每次迭代时只采集一小部分样本，计算在这组样本上损失函数的梯度并更新参数，这种优化方式称为<br>小批量梯度下降法（Mini-Batch Gradient Descent，Mini-Batch GD）。</p>
<p>第$t$次迭代时，随机选取一个包含$K$个样本的子集$\mathcal{B}_t$，计算这个子集上每个样本损失函数的梯度并进行平均，然后再进行参数更新。</p>
<script type="math/tex; mode=display">
\theta_{t+1} \leftarrow \theta_t  - \alpha \frac{1}{K} \sum_{(\boldsymbol{x},y)\in \mathcal{S}_t} \frac{\partial \mathcal{L}\Big(y,f(\boldsymbol{x};\theta)\Big)}{\partial \theta},</script><p>其中$K$为<strong>批量大小(Batch Size)</strong>。$K$通常不会设置很大，一般在$1\sim100$之间。在实际应用中为了提高计算效率，通常设置为2的幂$2^n$。</p>
<p>在实际应用中，小批量随机梯度下降法有收敛快、计算开销小的优点，因此逐渐成为大规模的机器学习中的主要优化算法。<br>此外，随机梯度下降相当于在批量梯度下降的梯度上引入了随机噪声。在非凸优化问题中，随机梯度下降更容易逃离局部最优点。</p>
<p>小批量随机梯度下降法的训练过程如下：</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/49287f7b41234d718fcc79b3f8edc64f366b05f460fb49cea88805777d508d82" alt=""></p>
<h4 id="4-5-1-1-数据分组"><a href="#4-5-1-1-数据分组" class="headerlink" title="4.5.1.1 数据分组"></a>4.5.1.1 数据分组</h4><p>为了小批量梯度下降法，我们需要对数据进行随机分组。目前，机器学习中通常做法是构建一个<strong>数据迭代器</strong>，每个迭代过程中从全部数据集中获取一批指定数量的数据。</p>
<p>数据迭代器的实现原理如下图所示：</p>
<p><img src="https://ai-studio-static-online.cdn.bcebos.com/337735d2bf6c49dda5415d791f6a320ffe739a809b3541faa26bfb8331506cb3" alt=""></p>
<ol>
<li>首先，将数据集封装为Dataset类，传入一组索引值，根据索引从数据集合中获取数据；</li>
<li>其次，构建DataLoader类，需要指定数据批量的大小和是否需要对数据进行乱序，通过该类即可批量获取数据。</li>
</ol>
<p>在实践过程中，通常使用进行参数优化。在飞桨中，使用<code>paddle.io.DataLoader</code>加载minibatch的数据，<br><code>paddle.io.DataLoader</code>  API可以生成一个迭代器，其中通过设置<code>batch_size</code>参数来指定minibatch的长度，通过设置shuffle参数为True，可以在生成<code>minibatch</code>的索引列表时将索引顺序打乱。</p>
<h3 id="4-5-2-数据处理"><a href="#4-5-2-数据处理" class="headerlink" title="4.5.2 数据处理"></a>4.5.2 数据处理</h3><p>构造IrisDataset类进行数据读取，继承自<code>paddle.io.Dataset</code>类。<code>paddle.io.Dataset</code>是用来封装 Dataset的方法和行为的抽象类，通过一个索引获取指定的样本，同时对该样本进行数据处理。当继承<code>paddle.io.Dataset</code>来定义数据读取类时，实现如下方法：</p>
<ul>
<li><code>__getitem__</code>：根据给定索引获取数据集中指定样本，并对样本进行数据处理；</li>
<li><code>__len__</code>：返回数据集样本个数。</li>
</ul>
<p>代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> paddle.io <span class="keyword">as</span> io</span><br><span class="line"><span class="keyword">from</span> nndl <span class="keyword">import</span> load_data</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IrisDataset</span>(io.Dataset):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, mode=<span class="string">&#x27;train&#x27;</span>, num_train=<span class="number">120</span>, num_dev=<span class="number">15</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(IrisDataset, self).__init__()</span><br><span class="line">        <span class="comment"># 调用第三章中的数据读取函数，其中不需要将标签转成one-hot类型</span></span><br><span class="line">        X, y = load_data(shuffle=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">            self.X, self.y = X[:num_train], y[:num_train]</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&#x27;dev&#x27;</span>:</span><br><span class="line">            self.X, self.y = X[num_train:num_train + num_dev], y[num_train:num_train + num_dev]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.X, self.y = X[num_train + num_dev:], y[num_train + num_dev:]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="keyword">return</span> self.X[idx], self.y[idx]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.y)</span><br></pre></td></tr></table></figure>
<pre><code>/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from &#39;collections&#39; instead of from &#39;collections.abc&#39; is deprecated, and in 3.8 it will stop working
  from collections import MutableMapping
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from &#39;collections&#39; instead of from &#39;collections.abc&#39; is deprecated, and in 3.8 it will stop working
  from collections import Iterable, Mapping
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from &#39;collections&#39; instead of from &#39;collections.abc&#39; is deprecated, and in 3.8 it will stop working
  from collections import Sized
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">paddle.seed(<span class="number">12</span>)</span><br><span class="line">train_dataset = IrisDataset(mode=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">dev_dataset = IrisDataset(mode=<span class="string">&#x27;dev&#x27;</span>)</span><br><span class="line">test_dataset = IrisDataset(mode=<span class="string">&#x27;test&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>W0516 19:23:24.529255  3381 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 11.2, Runtime API Version: 11.2
W0516 19:23:24.532312  3381 device_context.cc:465] device: 0, cuDNN Version: 8.2.
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打印训练集长度</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;length of train set: &quot;</span>, <span class="built_in">len</span>(train_dataset))</span><br></pre></td></tr></table></figure>
<pre><code>length of train set:  120
</code></pre><h4 id="4-5-2-2-用DataLoader进行封装"><a href="#4-5-2-2-用DataLoader进行封装" class="headerlink" title="4.5.2.2 用DataLoader进行封装"></a>4.5.2.2 用DataLoader进行封装</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 批量大小</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">train_loader = io.DataLoader(train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">dev_loader = io.DataLoader(dev_dataset, batch_size=batch_size)</span><br><span class="line">test_loader = io.DataLoader(test_dataset, batch_size=batch_size)</span><br></pre></td></tr></table></figure>
<h3 id="4-5-3-模型构建"><a href="#4-5-3-模型构建" class="headerlink" title="4.5.3 模型构建"></a>4.5.3 模型构建</h3><p>构建一个简单的前馈神经网络进行鸢尾花分类实验。其中输入层神经元个数为4，输出层神经元个数为3，隐含层神经元个数为6。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义前馈神经网络</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model_MLP_L2_V3</span>(nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, output_size, hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model_MLP_L2_V3, self).__init__()</span><br><span class="line">        <span class="comment"># 构建第一个全连接层</span></span><br><span class="line">        self.fc1 = nn.Linear(</span><br><span class="line">            input_size,</span><br><span class="line">            hidden_size,</span><br><span class="line">            weight_attr=paddle.ParamAttr(initializer=nn.initializer.Normal(mean=<span class="number">0.0</span>, std=<span class="number">0.01</span>)),</span><br><span class="line">            bias_attr=paddle.ParamAttr(initializer=nn.initializer.Constant(value=<span class="number">1.0</span>))</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 构建第二全连接层</span></span><br><span class="line">        self.fc2 = nn.Linear(</span><br><span class="line">            hidden_size,</span><br><span class="line">            output_size,</span><br><span class="line">            weight_attr=paddle.ParamAttr(initializer=nn.initializer.Normal(mean=<span class="number">0.0</span>, std=<span class="number">0.01</span>)),</span><br><span class="line">            bias_attr=paddle.ParamAttr(initializer=nn.initializer.Constant(value=<span class="number">1.0</span>))</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 定义网络使用的激活函数</span></span><br><span class="line">        self.act = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        outputs = self.fc1(inputs)</span><br><span class="line">        outputs = self.act(outputs)</span><br><span class="line">        outputs = self.fc2(outputs)</span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line">fnn_model = Model_MLP_L2_V3(input_size=<span class="number">4</span>, output_size=<span class="number">3</span>, hidden_size=<span class="number">6</span>)</span><br></pre></td></tr></table></figure>
<h3 id="4-5-4-完善Runner类"><a href="#4-5-4-完善Runner类" class="headerlink" title="4.5.4 完善Runner类"></a>4.5.4 完善Runner类</h3><p>基于RunnerV2类进行完善实现了RunnerV3类。其中训练过程使用自动梯度计算，使用<code>DataLoader</code>加载批量数据，使用随机梯度下降法进行参数优化；模型保存时，使用<code>state_dict</code>方法获取模型参数；模型加载时，使用<code>set_state_dict</code>方法加载模型参数.</p>
<p>由于这里使用随机梯度下降法对参数优化，所以数据以批次的形式输入到模型中进行训练，那么评价指标计算也是分别在每个批次进行的，要想获得每个epoch整体的评价结果，需要对历史评价结果进行累积。这里定义<code>Accuracy</code>类实现该功能。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> paddle.metric <span class="keyword">import</span> Metric</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Accuracy</span>(<span class="title class_ inherited__">Metric</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, is_logist=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        输入：</span></span><br><span class="line"><span class="string">           - is_logist: outputs是logist还是激活后的值</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 用于统计正确的样本个数</span></span><br><span class="line">        self.num_correct = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 用于统计样本的总数</span></span><br><span class="line">        self.num_count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        self.is_logist = is_logist</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, outputs, labels</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        输入：</span></span><br><span class="line"><span class="string">           - outputs: 预测值, shape=[N,class_num]</span></span><br><span class="line"><span class="string">           - labels: 标签值, shape=[N,1]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 判断是二分类任务还是多分类任务，shape[1]=1时为二分类任务，shape[1]&gt;1时为多分类任务</span></span><br><span class="line">        <span class="keyword">if</span> outputs.shape[<span class="number">1</span>] == <span class="number">1</span>: <span class="comment"># 二分类</span></span><br><span class="line">            outputs = paddle.squeeze(outputs, axis=-<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> self.is_logist:</span><br><span class="line">                <span class="comment"># logist判断是否大于0</span></span><br><span class="line">                preds = paddle.cast((outputs&gt;=<span class="number">0</span>), dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 如果不是logist，判断每个概率值是否大于0.5，当大于0.5时，类别为1，否则类别为0</span></span><br><span class="line">                preds = paddle.cast((outputs&gt;=<span class="number">0.5</span>), dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 多分类时，使用&#x27;paddle.argmax&#x27;计算最大元素索引作为类别</span></span><br><span class="line">            preds = paddle.argmax(outputs, axis=<span class="number">1</span>, dtype=<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取本批数据中预测正确的样本个数</span></span><br><span class="line">        labels = paddle.squeeze(labels, axis=-<span class="number">1</span>)</span><br><span class="line">        batch_correct = paddle.<span class="built_in">sum</span>(paddle.cast(preds==labels, dtype=<span class="string">&quot;float32&quot;</span>)).numpy()[<span class="number">0</span>]</span><br><span class="line">        batch_count = <span class="built_in">len</span>(labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新num_correct 和 num_count</span></span><br><span class="line">        self.num_correct += batch_correct</span><br><span class="line">        self.num_count += batch_count</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accumulate</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 使用累计的数据，计算总的指标</span></span><br><span class="line">        <span class="keyword">if</span> self.num_count == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> self.num_correct / self.num_count</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 重置正确的数目和总数</span></span><br><span class="line">        self.num_correct = <span class="number">0</span></span><br><span class="line">        self.num_count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">name</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Accuracy&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>RunnerV3类的代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RunnerV3</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model, optimizer, loss_fn, metric, **kwargs</span>):</span><br><span class="line">        self.model = model</span><br><span class="line">        self.optimizer = optimizer</span><br><span class="line">        self.loss_fn = loss_fn</span><br><span class="line">        self.metric = metric <span class="comment"># 只用于计算评价指标</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 记录训练过程中的评价指标变化情况</span></span><br><span class="line">        self.dev_scores = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 记录训练过程中的损失函数变化情况</span></span><br><span class="line">        self.train_epoch_losses = [] <span class="comment"># 一个epoch记录一次loss</span></span><br><span class="line">        self.train_step_losses = []  <span class="comment"># 一个step记录一次loss</span></span><br><span class="line">        self.dev_losses = []</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 记录全局最优指标</span></span><br><span class="line">        self.best_score = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, train_loader, dev_loader=<span class="literal">None</span>, **kwargs</span>):</span><br><span class="line">        <span class="comment"># 将模型切换为训练模式</span></span><br><span class="line">        self.model.train()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 传入训练轮数，如果没有传入值则默认为0</span></span><br><span class="line">        num_epochs = kwargs.get(<span class="string">&quot;num_epochs&quot;</span>, <span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 传入log打印频率，如果没有传入值则默认为100</span></span><br><span class="line">        log_steps = kwargs.get(<span class="string">&quot;log_steps&quot;</span>, <span class="number">100</span>)</span><br><span class="line">        <span class="comment"># 评价频率</span></span><br><span class="line">        eval_steps = kwargs.get(<span class="string">&quot;eval_steps&quot;</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 传入模型保存路径，如果没有传入值则默认为&quot;best_model.pdparams&quot;</span></span><br><span class="line">        save_path = kwargs.get(<span class="string">&quot;save_path&quot;</span>, <span class="string">&quot;best_model.pdparams&quot;</span>)</span><br><span class="line"></span><br><span class="line">        custom_print_log = kwargs.get(<span class="string">&quot;custom_print_log&quot;</span>, <span class="literal">None</span>) </span><br><span class="line">       </span><br><span class="line">        <span class="comment"># 训练总的步数</span></span><br><span class="line">        num_training_steps = num_epochs * <span class="built_in">len</span>(train_loader)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> eval_steps:</span><br><span class="line">            <span class="keyword">if</span> self.metric <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">raise</span> RuntimeError(<span class="string">&#x27;Error: Metric can not be None!&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> dev_loader <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">raise</span> RuntimeError(<span class="string">&#x27;Error: dev_loader can not be None!&#x27;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 运行的step数目</span></span><br><span class="line">        global_step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 进行num_epochs轮训练</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">            <span class="comment"># 用于统计训练集的损失</span></span><br><span class="line">            total_loss = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> step, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">                X, y = data</span><br><span class="line">                <span class="comment"># 获取模型预测</span></span><br><span class="line">                logits = self.model(X)</span><br><span class="line">                loss = self.loss_fn(logits, y) <span class="comment"># 默认求mean</span></span><br><span class="line">                total_loss += loss </span><br><span class="line"></span><br><span class="line">                <span class="comment"># 训练过程中，每个step的loss进行保存</span></span><br><span class="line">                self.train_step_losses.append((global_step,loss.item()))</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> log_steps <span class="keyword">and</span> global_step%log_steps==<span class="number">0</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;[Train] epoch: <span class="subst">&#123;epoch&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>, step: <span class="subst">&#123;global_step&#125;</span>/<span class="subst">&#123;num_training_steps&#125;</span>, loss: <span class="subst">&#123;loss.item():<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 梯度反向传播，计算每个参数的梯度值</span></span><br><span class="line">                loss.backward() </span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> custom_print_log:</span><br><span class="line">                   custom_print_log(self)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 小批量梯度下降进行参数更新</span></span><br><span class="line">                self.optimizer.step()</span><br><span class="line">                <span class="comment"># 梯度归零</span></span><br><span class="line">                self.optimizer.clear_grad()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 判断是否需要评价</span></span><br><span class="line">                <span class="keyword">if</span> eval_steps&gt;<span class="number">0</span> <span class="keyword">and</span> global_step&gt;<span class="number">0</span> <span class="keyword">and</span> \</span><br><span class="line">                    (global_step%eval_steps == <span class="number">0</span> <span class="keyword">or</span> global_step==(num_training_steps-<span class="number">1</span>)):</span><br><span class="line"></span><br><span class="line">                    dev_score, dev_loss = self.evaluate(dev_loader, global_step=global_step)</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;[Evaluate]  dev score: <span class="subst">&#123;dev_score:<span class="number">.5</span>f&#125;</span>, dev loss: <span class="subst">&#123;dev_loss:<span class="number">.5</span>f&#125;</span>&quot;</span>) </span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 将模型切换为训练模式</span></span><br><span class="line">                    self.model.train()</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 如果当前指标为最优指标，保存该模型</span></span><br><span class="line">                    <span class="keyword">if</span> dev_score &gt; self.best_score:</span><br><span class="line">                        self.save_model(save_path)</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">f&quot;[Evaluate] best accuracy performence has been updated: <span class="subst">&#123;self.best_score:<span class="number">.5</span>f&#125;</span> --&gt; <span class="subst">&#123;dev_score:<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br><span class="line">                        self.best_score = dev_score</span><br><span class="line"></span><br><span class="line">                global_step += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 当前epoch 训练loss累计值 </span></span><br><span class="line">            trn_loss = (total_loss / <span class="built_in">len</span>(train_loader)).item()</span><br><span class="line">            <span class="comment"># epoch粒度的训练loss保存</span></span><br><span class="line">            self.train_epoch_losses.append(trn_loss)</span><br><span class="line">            </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;[Train] Training done!&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型评估阶段，使用&#x27;paddle.no_grad()&#x27;控制不计算和存储梯度</span></span><br><span class="line"><span class="meta">    @paddle.no_grad()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">self, dev_loader, **kwargs</span>):</span><br><span class="line">        <span class="keyword">assert</span> self.metric <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将模型设置为评估模式</span></span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">        global_step = kwargs.get(<span class="string">&quot;global_step&quot;</span>, -<span class="number">1</span>) </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 用于统计训练集的损失</span></span><br><span class="line">        total_loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 重置评价</span></span><br><span class="line">        self.metric.reset() </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 遍历验证集每个批次    </span></span><br><span class="line">        <span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dev_loader):</span><br><span class="line">            X, y = data</span><br><span class="line">    </span><br><span class="line">            <span class="comment"># 计算模型输出</span></span><br><span class="line">            logits = self.model(X)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算损失函数</span></span><br><span class="line">            loss = self.loss_fn(logits, y).item()</span><br><span class="line">            <span class="comment"># 累积损失</span></span><br><span class="line">            total_loss += loss </span><br><span class="line"></span><br><span class="line">            <span class="comment"># 累积评价</span></span><br><span class="line">            self.metric.update(logits, y)</span><br><span class="line"></span><br><span class="line">        dev_loss = (total_loss/<span class="built_in">len</span>(dev_loader))</span><br><span class="line">        dev_score = self.metric.accumulate() </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 记录验证集loss</span></span><br><span class="line">        <span class="keyword">if</span> global_step!=-<span class="number">1</span>:</span><br><span class="line">            self.dev_losses.append((global_step, dev_loss))</span><br><span class="line">            self.dev_scores.append(dev_score)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> dev_score, dev_loss</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 模型评估阶段，使用&#x27;paddle.no_grad()&#x27;控制不计算和存储梯度</span></span><br><span class="line"><span class="meta">    @paddle.no_grad()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, x, **kwargs</span>):</span><br><span class="line">        <span class="comment"># 将模型设置为评估模式</span></span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="comment"># 运行模型前向计算，得到预测值</span></span><br><span class="line">        logits = self.model(x)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_model</span>(<span class="params">self, save_path</span>):</span><br><span class="line">        paddle.save(self.model.state_dict(), save_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_model</span>(<span class="params">self, model_path</span>):</span><br><span class="line">        model_state_dict = paddle.load(model_path)</span><br><span class="line">        self.model.set_state_dict(model_state_dict)</span><br></pre></td></tr></table></figure>
<h3 id="4-5-5-模型训练"><a href="#4-5-5-模型训练" class="headerlink" title="4.5.5 模型训练"></a>4.5.5 模型训练</h3><p>实例化RunnerV3类，并传入训练配置，代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle.optimizer <span class="keyword">as</span> opt</span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义网络</span></span><br><span class="line">model = fnn_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">optimizer = opt.SGD(learning_rate=lr, parameters=model.parameters())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数。softmax+交叉熵</span></span><br><span class="line">loss_fn = F.cross_entropy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义评价指标</span></span><br><span class="line">metric = Accuracy(is_logist=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">runner = RunnerV3(model, optimizer, loss_fn, metric)</span><br></pre></td></tr></table></figure>
<p>使用训练集和验证集进行模型训练，共训练150个epoch。在实验中，保存准确率最高的模型作为最佳模型。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动训练</span></span><br><span class="line">log_steps = <span class="number">100</span></span><br><span class="line">eval_steps = <span class="number">50</span></span><br><span class="line">runner.train(train_loader, dev_loader, </span><br><span class="line">            num_epochs=<span class="number">150</span>, log_steps=log_steps, eval_steps = eval_steps,</span><br><span class="line">            save_path=<span class="string">&quot;best_model.pdparams&quot;</span>) </span><br></pre></td></tr></table></figure>
<pre><code>[Train] epoch: 0/150, step: 0/1200, loss: 1.09505
[Evaluate]  dev score: 0.40000, dev loss: 1.09034
[Evaluate] best accuracy performence has been updated: 0.00000 --&gt; 0.40000
[Train] epoch: 12/150, step: 100/1200, loss: 1.17283
[Evaluate]  dev score: 0.40000, dev loss: 1.08822
[Evaluate]  dev score: 0.33333, dev loss: 1.11525
[Train] epoch: 25/150, step: 200/1200, loss: 1.10550
[Evaluate]  dev score: 0.40000, dev loss: 1.09292
[Evaluate]  dev score: 0.40000, dev loss: 1.09518
[Train] epoch: 37/150, step: 300/1200, loss: 1.11925
[Evaluate]  dev score: 0.33333, dev loss: 1.07696
[Evaluate]  dev score: 0.60000, dev loss: 1.04172
[Evaluate] best accuracy performence has been updated: 0.40000 --&gt; 0.60000
[Train] epoch: 50/150, step: 400/1200, loss: 0.98805
[Evaluate]  dev score: 0.40000, dev loss: 0.94627
[Evaluate]  dev score: 1.00000, dev loss: 0.79737
[Evaluate] best accuracy performence has been updated: 0.60000 --&gt; 1.00000
[Train] epoch: 62/150, step: 500/1200, loss: 0.64998
[Evaluate]  dev score: 0.80000, dev loss: 0.65108
[Evaluate]  dev score: 0.93333, dev loss: 0.55086
[Train] epoch: 75/150, step: 600/1200, loss: 0.45059
[Evaluate]  dev score: 0.80000, dev loss: 0.48998
[Evaluate]  dev score: 0.93333, dev loss: 0.44585
[Train] epoch: 87/150, step: 700/1200, loss: 0.40733
[Evaluate]  dev score: 0.93333, dev loss: 0.40810
[Evaluate]  dev score: 1.00000, dev loss: 0.38619
[Train] epoch: 100/150, step: 800/1200, loss: 0.38417
[Evaluate]  dev score: 0.93333, dev loss: 0.35828
[Evaluate]  dev score: 1.00000, dev loss: 0.34140
[Train] epoch: 112/150, step: 900/1200, loss: 0.28922
[Evaluate]  dev score: 0.93333, dev loss: 0.31777
[Evaluate]  dev score: 1.00000, dev loss: 0.30399
[Train] epoch: 125/150, step: 1000/1200, loss: 0.28038
[Evaluate]  dev score: 1.00000, dev loss: 0.28455
[Evaluate]  dev score: 1.00000, dev loss: 0.27460
[Train] epoch: 137/150, step: 1100/1200, loss: 0.19444
[Evaluate]  dev score: 0.93333, dev loss: 0.25200
[Evaluate]  dev score: 1.00000, dev loss: 0.24346
[Evaluate]  dev score: 1.00000, dev loss: 0.22806
[Train] Training done!
</code></pre><p>可视化观察训练集损失和训练集loss变化情况。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制训练集和验证集的损失变化以及验证集上的准确率变化曲线</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_training_loss_acc</span>(<span class="params">runner, fig_name, </span></span><br><span class="line"><span class="params">    fig_size=(<span class="params"><span class="number">16</span>, <span class="number">6</span></span>), </span></span><br><span class="line"><span class="params">    sample_step=<span class="number">20</span>, </span></span><br><span class="line"><span class="params">    loss_legend_loc=<span class="string">&quot;upper right&quot;</span>, </span></span><br><span class="line"><span class="params">    acc_legend_loc=<span class="string">&quot;lower right&quot;</span>,</span></span><br><span class="line"><span class="params">    train_color=<span class="string">&quot;#8E004D&quot;</span>,</span></span><br><span class="line"><span class="params">    dev_color=<span class="string">&#x27;#E20079&#x27;</span>,</span></span><br><span class="line"><span class="params">    fontsize=<span class="string">&#x27;x-large&#x27;</span>,</span></span><br><span class="line"><span class="params">    train_linestyle=<span class="string">&quot;-&quot;</span>,</span></span><br><span class="line"><span class="params">    dev_linestyle=<span class="string">&#x27;--&#x27;</span></span>):</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=fig_size)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">    train_items = runner.train_step_losses[::sample_step]</span><br><span class="line">    train_steps=[x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> train_items]</span><br><span class="line">    train_losses = [x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> train_items]</span><br><span class="line"></span><br><span class="line">    plt.plot(train_steps, train_losses, color=train_color, linestyle=train_linestyle, label=<span class="string">&quot;Train loss&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(runner.dev_losses)&gt;<span class="number">0</span>:</span><br><span class="line">        dev_steps=[x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> runner.dev_losses]</span><br><span class="line">        dev_losses = [x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> runner.dev_losses]</span><br><span class="line">        plt.plot(dev_steps, dev_losses, color=dev_color, linestyle=dev_linestyle, label=<span class="string">&quot;Dev loss&quot;</span>)</span><br><span class="line">    <span class="comment"># 绘制坐标轴和图例</span></span><br><span class="line">    plt.ylabel(<span class="string">&quot;loss&quot;</span>, fontsize=fontsize)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;step&quot;</span>, fontsize=fontsize)</span><br><span class="line">    plt.legend(loc=loss_legend_loc, fontsize=fontsize)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制评价准确率变化曲线</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(runner.dev_scores)&gt;<span class="number">0</span>:</span><br><span class="line">        plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">        plt.plot(dev_steps, runner.dev_scores,</span><br><span class="line">            color=dev_color, linestyle=dev_linestyle, label=<span class="string">&quot;Dev accuracy&quot;</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># 绘制坐标轴和图例</span></span><br><span class="line">        plt.ylabel(<span class="string">&quot;score&quot;</span>, fontsize=fontsize)</span><br><span class="line">        plt.xlabel(<span class="string">&quot;step&quot;</span>, fontsize=fontsize)</span><br><span class="line">        plt.legend(loc=acc_legend_loc, fontsize=fontsize)</span><br><span class="line"></span><br><span class="line">    plt.savefig(fig_name)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot_training_loss_acc(runner, <span class="string">&#x27;fw-loss.pdf&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>​<br><img src="/img-nndl/output_19_0.png" alt="png"><br>​    </p>
<p>从输出结果可以看出准确率随着迭代次数增加逐渐上升，损失函数下降。</p>
<h3 id="4-5-6-模型评价"><a href="#4-5-6-模型评价" class="headerlink" title="4.5.6 模型评价"></a>4.5.6 模型评价</h3><p>使用测试数据对在训练过程中保存的最佳模型进行评价，观察模型在测试集上的准确率以及Loss情况。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载最优模型</span></span><br><span class="line">runner.load_model(<span class="string">&#x27;best_model.pdparams&#x27;</span>)</span><br><span class="line"><span class="comment"># 模型评价</span></span><br><span class="line">score, loss = runner.evaluate(test_loader)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[Test] accuracy/loss: &#123;:.4f&#125;/&#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(score, loss))</span><br></pre></td></tr></table></figure>
<pre><code>[Test] accuracy/loss: 0.8667/0.8319
</code></pre><h3 id="4-5-7-模型预测"><a href="#4-5-7-模型预测" class="headerlink" title="4.5.7 模型预测"></a>4.5.7 模型预测</h3><p>同样地，也可以使用保存好的模型，对测试集中的某一个数据进行模型预测，观察模型效果。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取测试集中第一条数据</span></span><br><span class="line">X, label = <span class="built_in">next</span>(test_loader())</span><br><span class="line">logits = runner.predict(X)</span><br><span class="line"></span><br><span class="line">pred_class = paddle.argmax(logits[<span class="number">0</span>]).numpy()</span><br><span class="line">label = label[<span class="number">0</span>][<span class="number">0</span>].numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出真实类别与预测类别</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The true category is &#123;&#125; and the predicted category is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(label, pred_class))</span><br></pre></td></tr></table></figure>
<pre><code>The true category is [2] and the predicted category is [2]
</code></pre><h2 id="4-6-小结"><a href="#4-6-小结" class="headerlink" title="4.6 小结"></a>4.6 小结</h2><p>本章介绍前馈神经网络的基本概念、网络结构及代码实现，利用前馈神经网络完成一个分类任务，并通过两个简单的实验，观察前馈神经网络的梯度消失问题和死亡ReLU问题，以及对应的优化策略。<br>此外，还实践了基于前馈神经网络完成鸢尾花分类任务。</p>
<h2 id="4-7-实验拓展"><a href="#4-7-实验拓展" class="headerlink" title="4.7 实验拓展"></a>4.7 实验拓展</h2><p>尝试基于MNIST手写数字识别数据集，设计合适的前馈神经网络进行实验，并取得95%以上的准确率。</p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2022/08/12/nndl/chapter5A/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">&lt;</strong>
      <div class="article-nav-title">
        
          第5章（上）：卷积神经网络理论解读
        
      </div>
    </a>
  
  
    <a href="/2022/08/12/nndl/chapter4A/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">第4章（上）：前馈神经网络理论解读</div>
      <strong class="article-nav-caption">&gt;</strong>
    </a>
  
</nav>

  
</article>






    <section id="comments" style="margin: 60px;">
      <div id="gitalk-container"></div>
      <script>
      var gitalk = new Gitalk({
          clientID: 'ecf230c60af3ed1123fa',
          clientSecret: '1e1daf2e6dd957a3f7d6b22b524387d14aafdb13',
          repo: 'hfut-zyw.github.io',
          owner: 'hfut-zyw',
          admin: ['hfut-zyw'],
          id: md5(location.pathname),      // Ensure uniqueness and length less than 50
          distractionFreeMode: false  // Facebook-like distraction free mode
        })
      gitalk.render('gitalk-container')
      </script>
      
    </section>

</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        <a href="https://space.bilibili.com/782159" target="_blank">访问我的哔哩哔哩</a> 
      </div>
        <div class="footer-right">
        &copy; 2022 LabmemNo.001
        </div>
    </div>
  </div>
</footer>
    </div>
    
  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">



<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: ,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>

<script src="/js/main.js"></script>




  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"left","width":85,"height":170},"mobile":{"show":false},"log":false});</script></body>
</html>