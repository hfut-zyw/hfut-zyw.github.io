<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>第3章（下）：基于Softmax回归完成鸢尾花分类任务 | Homepage | 张有为</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="3.3 实践：基于Softmax回归完成鸢尾花分类任务在本节，我们用入门深度学习的基础实验之一“鸢尾花分类任务”来进行实践，使用经典学术数据集Iris作为训练数据，实现基于Softmax回归的鸢尾花分类任务。">
<meta property="og:type" content="article">
<meta property="og:title" content="第3章（下）：基于Softmax回归完成鸢尾花分类任务">
<meta property="og:url" content="http://example.com/2022/08/12/nndl/chapter3B/index.html">
<meta property="og:site_name" content="Homepage | 张有为">
<meta property="og:description" content="3.3 实践：基于Softmax回归完成鸢尾花分类任务在本节，我们用入门深度学习的基础实验之一“鸢尾花分类任务”来进行实践，使用经典学术数据集Iris作为训练数据，实现基于Softmax回归的鸢尾花分类任务。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img-nndl/output_17_0.png">
<meta property="article:published_time" content="2022-08-12T01:26:58.000Z">
<meta property="article:modified_time" content="2022-09-22T13:03:42.941Z">
<meta property="article:author" content="LabmemNo.001">
<meta property="article:tag" content="nndl案例与实践">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img-nndl/output_17_0.png">
  
    <link rel="alternative" href="/atom.xml" title="Homepage | 张有为" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/icon.gif">
  
  
<link rel="stylesheet" href="/css/style.css">

  
  

  
<script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>

  
<script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>


  
<meta name="generator" content="Hexo 6.2.0"></head>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/img/face.png" class="js-avatar show" style="width: 100%;height: 100%;opacity: 1;">
		</a>

		<hgroup>
			<h1 class="header-author"><a href="/">LabmemNo.001</a></h1>
		</hgroup>

		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">

					<nav class="header-menu">
						<ul>
						
							<li><a href="/2022/08/09/me/aboutme">个人简介</a>
							</li>
				        
							<li><a href="/categories/notes">一些随写</a>
							</li>
				        
							<li><a href="/categories/analysis">抽象分析基础</a>
							</li>
				        
							<li><a href="/categories/probability">高等概率统计</a>
							</li>
				        
							<li><a href="/categories/opt">矩阵论与最优化</a>
							</li>
				        
						</ul>
					</nav>

					<nav class="header-menu">
						<ul>
						<li><a style="color:rgb(228, 117, 238)">Deep Learning </a>
							<nav class="header-submenu">
								<ul>
									
										<li><a href="/categories/pytorch"><div>Pytorch</div></a></li>  
									
										<li><a href="/categories/pandas"><div>Pandas</div></a></li>  
									
										<li><a href="/categories/matplotlib"><div>Matplotlib</div></a></li>  
									
										<li><a href="/categories/nndl"><div>nndl案例与实践</div></a></li>  
									
								</ul>
							</nav>	
						</li>     
						</ul>
					</nav>
					
								
					


					<nav class="half-header-menu">
						<a class="hide">Home</a>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/hfut-zyw" title="github">github</a>
					        
								<a class="mail" target="_blank" href="mailto:lucario@qq.com" title="mail">mail</a>
					        
						</div>
						<!-- music -->
						
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Matplotlib%E7%AC%94%E8%AE%B0/" style="font-size: 10px;">Matplotlib笔记</a> <a href="/tags/Pandas%E7%AC%94%E8%AE%B0/" style="font-size: 10px;">Pandas笔记</a> <a href="/tags/Pytorch%E7%AC%94%E8%AE%B0/" style="font-size: 12.5px;">Pytorch笔记</a> <a href="/tags/nndl%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/" style="font-size: 20px;">nndl案例与实践</a> <a href="/tags/%E4%BC%98%E5%8C%96%E7%AC%94%E8%AE%B0/" style="font-size: 15px;">优化笔记</a> <a href="/tags/%E5%85%B3%E4%BA%8E%E6%88%91/" style="font-size: 10px;">关于我</a> <a href="/tags/%E5%88%86%E6%9E%90%E7%AC%94%E8%AE%B0/" style="font-size: 17.5px;">分析笔记</a> <a href="/tags/%E9%9A%8F%E5%86%99/" style="font-size: 15px;">随写</a>
					</div>
				</section>
				
				
				

				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide"></h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="/img/face.png" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author"></h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/2022/08/09/me/aboutme">个人简介</a></li>
		        
					<li><a href="/categories/notes">一些随写</a></li>
		        
					<li><a href="/categories/analysis">抽象分析基础</a></li>
		        
					<li><a href="/categories/probability">高等概率统计</a></li>
		        
					<li><a href="/categories/opt">矩阵论与最优化</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/hfut-zyw" title="github">github</a>
			        
						<a class="mail" target="_blank" href="mailto:lucario@qq.com" title="mail">mail</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-nndl/chapter3B" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/08/12/nndl/chapter3B/" class="article-date">
  	<time datetime="2022-08-12T01:26:58.000Z" itemprop="datePublished">2022-08-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      第3章（下）：基于Softmax回归完成鸢尾花分类任务
      
          <span class="title-pop-out"></a>
      
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/nndl%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5/" rel="tag">nndl案例与实践</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/nndl/">nndl</a>
	</div>


        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="3-3-实践：基于Softmax回归完成鸢尾花分类任务"><a href="#3-3-实践：基于Softmax回归完成鸢尾花分类任务" class="headerlink" title="3.3 实践：基于Softmax回归完成鸢尾花分类任务"></a>3.3 实践：基于Softmax回归完成鸢尾花分类任务</h2><p>在本节，我们用入门深度学习的基础实验之一“鸢尾花分类任务”来进行实践，使用经典学术数据集Iris作为训练数据，实现基于Softmax回归的鸢尾花分类任务。<span id="more"></span></p>
<p>实践流程主要包括以下7个步骤：数据处理、模型构建、损失函数定义、优化器构建、模型训练、模型评价和模型预测等，</p>
<ul>
<li>数据处理：根据网络接收的数据格式，完成相应的预处理操作，保证模型正常读取；</li>
<li>模型构建：定义Softmax回归模型类；</li>
<li>训练配置：训练相关的一些配置，如：优化算法、评价指标等；</li>
<li>组装Runner类：Runner用于管理模型训练和测试过程；</li>
<li>模型训练和测试：利用Runner进行模型训练、评价和测试。</li>
</ul>
<hr>
<p><strong>说明：</strong></p>
<p>使用深度学习进行实践时的操作流程基本一致，后文不再赘述。</p>
<hr>
<p>本实践的主要配置如下：</p>
<ul>
<li>数据：Iris数据集；</li>
<li>模型：Softmax回归模型；</li>
<li>损失函数：交叉熵损失；</li>
<li>优化器：梯度下降法；</li>
<li>评价指标：准确率。</li>
</ul>
<h3 id="3-3-1-数据处理"><a href="#3-3-1-数据处理" class="headerlink" title="3.3.1 数据处理"></a>3.3.1 数据处理</h3><h4 id="3-3-1-1-数据集介绍"><a href="#3-3-1-1-数据集介绍" class="headerlink" title="3.3.1.1 数据集介绍"></a>3.3.1.1 数据集介绍</h4><p>Iris数据集，也称为鸢尾花数据集，包含了3种鸢尾花类别（Setosa、Versicolour、Virginica），每种类别有50个样本，共计150个样本。其中每个样本中包含了4个属性：花萼长度、花萼宽度、花瓣长度以及花瓣宽度，本实验通过鸢尾花这4个属性来判断该样本的类别。</p>
<p><strong>鸢尾花属性</strong></p>
<center>


|    属性1     |    属性2    |    属性3     |    属性4    |
| :----------: | :---------: | :----------: | :---------: |
| sepal_length | sepal_width | petal_length | petal_width |
|   花萼长度   |  花萼宽度   |   花瓣长度   |  花瓣宽度   |
|  </center>   |             |              |             |


**鸢尾花类别**

<center>


|      英文名      |    中文名    | 标签 |
| :--------------: | :----------: | :--: |
|   Setosa Iris    |  狗尾草鸢尾  |  0   |
| Versicolour Iris |   杂色鸢尾   |  1   |
|  Virginica Iris  | 弗吉尼亚鸢尾 |  2   |

</center>

<p><strong>鸢尾花属性类别对应预览</strong></p>
<center>


| sepal_length | sepal_width | petal_length | petal_width | species |
| :----------: | :---------: | :----------: | :---------: | :-----: |
|     5.1      |     3.5     |     1.4      |     0.2     | setosa  |
|     4.9      |      3      |     1.4      |     0.2     | setosa  |
|     4.7      |     3.2     |     1.3      |     0.2     | setosa  |
|     ...      |     ...     |     ...      |     ...     |   ...   |

</center>


<h4 id="3-3-1-2-数据清洗"><a href="#3-3-1-2-数据清洗" class="headerlink" title="3.3.1.2 数据清洗"></a>3.3.1.2 数据清洗</h4><ul>
<li><strong>缺失值分析</strong></li>
</ul>
<p>对数据集中的缺失值或异常值等情况进行分析和处理，保证数据可以被模型正常读取。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">iris_features = np.array(load_iris().data, dtype=np.float32)</span><br><span class="line">iris_labels = np.array(load_iris().target, dtype=np.int32)</span><br><span class="line"><span class="built_in">print</span>(pandas.isna(iris_features).<span class="built_in">sum</span>())</span><br><span class="line"><span class="built_in">print</span>(pandas.isna(iris_labels).<span class="built_in">sum</span>())</span><br></pre></td></tr></table></figure>
<pre><code>0
0
</code></pre><p>从输出结果看，鸢尾花数据集中不存在缺失值的情况。</p>
<ul>
<li><strong>异常值处理</strong></li>
</ul>
<p>通过箱线图直观的显示数据分布，并观测数据中的异常值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment">#可视化工具</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 箱线图查看异常值分布</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">boxplot</span>(<span class="params">features</span>):</span><br><span class="line">    feature_names = [<span class="string">&#x27;sepal_length&#x27;</span>, <span class="string">&#x27;sepal_width&#x27;</span>, <span class="string">&#x27;petal_length&#x27;</span>, <span class="string">&#x27;petal_width&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 连续画几个图片</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">5</span>, <span class="number">5</span>), dpi=<span class="number">200</span>)</span><br><span class="line">    <span class="comment"># 子图调整</span></span><br><span class="line">    plt.subplots_adjust(wspace=<span class="number">0.6</span>)</span><br><span class="line">    <span class="comment"># 每个特征画一个箱线图</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        plt.subplot(<span class="number">2</span>, <span class="number">2</span>, i+<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 画箱线图</span></span><br><span class="line">        plt.boxplot(features[:, i], </span><br><span class="line">                    showmeans=<span class="literal">True</span>, </span><br><span class="line">                    whiskerprops=&#123;<span class="string">&quot;color&quot;</span>:<span class="string">&quot;#E20079&quot;</span>, <span class="string">&quot;linewidth&quot;</span>:<span class="number">0.4</span>, <span class="string">&#x27;linestyle&#x27;</span>:<span class="string">&quot;--&quot;</span>&#125;,</span><br><span class="line">                    flierprops=&#123;<span class="string">&quot;markersize&quot;</span>:<span class="number">0.4</span>&#125;,</span><br><span class="line">                    meanprops=&#123;<span class="string">&quot;markersize&quot;</span>:<span class="number">1</span>&#125;)</span><br><span class="line">        <span class="comment"># 图名</span></span><br><span class="line">        plt.title(feature_names[i], fontdict=&#123;<span class="string">&quot;size&quot;</span>:<span class="number">5</span>&#125;, pad=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># y方向刻度</span></span><br><span class="line">        plt.yticks(fontsize=<span class="number">4</span>, rotation=<span class="number">90</span>)</span><br><span class="line">        plt.tick_params(pad=<span class="number">0.5</span>)</span><br><span class="line">        <span class="comment"># x方向刻度</span></span><br><span class="line">        plt.xticks([])</span><br><span class="line">    plt.savefig(<span class="string">&#x27;ml-vis.pdf&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">boxplot(iris_features)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;Figure size 1000x1000 with 4 Axes&gt;
</code></pre><p>从输出结果看，数据中基本不存在异常值，所以不需要进行异常值处理。</p>
<h4 id="3-3-1-3-数据读取"><a href="#3-3-1-3-数据读取" class="headerlink" title="3.3.1.3 数据读取"></a>3.3.1.3 数据读取</h4><p>本实验中将数据集划分为了三个部分：</p>
<ul>
<li>训练集：用于确定模型参数；</li>
<li>验证集：与训练集独立的样本集合，用于使用提前停止策略选择最优模型；</li>
<li>测试集：用于估计应用效果（没有在模型中应用过的数据，更贴近模型在真实场景应用的效果）。</li>
</ul>
<p>在本实验中，将$80\%$的数据用于模型训练，$10\%$的数据用于模型验证，$10\%$的数据用于模型测试。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> paddle </span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>(<span class="params">shuffle=<span class="literal">True</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    加载鸢尾花数据</span></span><br><span class="line"><span class="string">    输入：</span></span><br><span class="line"><span class="string">        - shuffle：是否打乱数据，数据类型为bool</span></span><br><span class="line"><span class="string">    输出：</span></span><br><span class="line"><span class="string">        - X：特征数据，shape=[150,4]</span></span><br><span class="line"><span class="string">        - y：标签数据, shape=[150]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 加载原始数据</span></span><br><span class="line">    X = np.array(load_iris().data, dtype=np.float32)</span><br><span class="line">    y = np.array(load_iris().target, dtype=np.int32)</span><br><span class="line"></span><br><span class="line">    X = paddle.to_tensor(X)</span><br><span class="line">    y = paddle.to_tensor(y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据归一化</span></span><br><span class="line">    X_min = paddle.<span class="built_in">min</span>(X, axis=<span class="number">0</span>)</span><br><span class="line">    X_max = paddle.<span class="built_in">max</span>(X, axis=<span class="number">0</span>)</span><br><span class="line">    X = (X-X_min) / (X_max-X_min)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果shuffle为True，随机打乱数据</span></span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        idx = paddle.randperm(X.shape[<span class="number">0</span>])</span><br><span class="line">        X = X[idx]</span><br><span class="line">        y = y[idx]</span><br><span class="line">    <span class="keyword">return</span> X, y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 固定随机种子</span></span><br><span class="line">paddle.seed(<span class="number">102</span>)</span><br><span class="line"></span><br><span class="line">num_train = <span class="number">120</span></span><br><span class="line">num_dev = <span class="number">15</span></span><br><span class="line">num_test = <span class="number">15</span></span><br><span class="line"></span><br><span class="line">X, y = load_data(shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X shape: &quot;</span>, X.shape, <span class="string">&quot;y shape: &quot;</span>, y.shape)</span><br><span class="line">X_train, y_train = X[:num_train], y[:num_train]</span><br><span class="line">X_dev, y_dev = X[num_train:num_train + num_dev], y[num_train:num_train + num_dev]</span><br><span class="line">X_test, y_test = X[num_train + num_dev:], y[num_train + num_dev:]</span><br></pre></td></tr></table></figure>
<pre><code>X shape:  [150, 4] y shape:  [150]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打印X_train和y_train的维度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X_train shape: &quot;</span>, X_train.shape, <span class="string">&quot;y_train shape: &quot;</span>, y_train.shape)</span><br></pre></td></tr></table></figure>
<pre><code>X_train shape:  [120, 4] y_train shape:  [120]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打印前5个数据的标签</span></span><br><span class="line"><span class="built_in">print</span>(y_train[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<pre><code>Tensor(shape=[5], dtype=int32, place=CPUPlace, stop_gradient=True,
       [0, 1, 1, 0, 1])
</code></pre><h3 id="3-3-2-模型构建"><a href="#3-3-2-模型构建" class="headerlink" title="3.3.2 模型构建"></a>3.3.2 模型构建</h3><p>使用Softmax回归模型进行鸢尾花分类实验，将模型的输入维度定义为4，输出维度定义为3。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nndl <span class="keyword">import</span> op</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入维度</span></span><br><span class="line">input_dim = <span class="number">4</span></span><br><span class="line"><span class="comment"># 类别数</span></span><br><span class="line">output_dim = <span class="number">3</span></span><br><span class="line"><span class="comment"># 实例化模型</span></span><br><span class="line">model = op.model_SR(input_dim=input_dim, output_dim=output_dim)</span><br></pre></td></tr></table></figure>
<h3 id="3-3-3-模型训练"><a href="#3-3-3-模型训练" class="headerlink" title="3.3.3 模型训练"></a>3.3.3 模型训练</h3><p>实例化RunnerV2类，使用训练集和验证集进行模型训练，共训练80个epoch，其中每隔10个epoch打印训练集上的指标，并且保存准确率最高的模型作为最佳模型。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nndl <span class="keyword">import</span> op, metric, opitimizer, RunnerV2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">lr = <span class="number">0.2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降法</span></span><br><span class="line">optimizer = opitimizer.SimpleBatchGD(init_lr=lr, model=model)</span><br><span class="line"><span class="comment"># 交叉熵损失</span></span><br><span class="line">loss_fn = op.MultiCrossEntropyLoss()</span><br><span class="line"><span class="comment"># 准确率</span></span><br><span class="line">metric = metric.accuracy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化RunnerV2</span></span><br><span class="line">runner = RunnerV2(model, optimizer, metric, loss_fn)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动训练</span></span><br><span class="line">runner.train([X_train, y_train], [X_dev, y_dev], num_epochs=<span class="number">200</span>, log_epochs=<span class="number">10</span>, save_path=<span class="string">&quot;best_model.pdparams&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>best accuracy performence has been updated: 0.00000 --&gt; 0.40000
[Train] epoch: 0, loss: 1.09861159324646, score: 0.3166666626930237
[Dev] epoch: 0, loss: 1.0828710794448853, score: 0.4000000059604645
best accuracy performence has been updated: 0.40000 --&gt; 0.46667
best accuracy performence has been updated: 0.46667 --&gt; 0.66667
best accuracy performence has been updated: 0.66667 --&gt; 0.73333
[Train] epoch: 10, loss: 0.9869741201400757, score: 0.6416666507720947
[Dev] epoch: 10, loss: 0.9746579527854919, score: 0.7333333492279053
[Train] epoch: 20, loss: 0.9098508954048157, score: 0.6499999761581421
[Dev] epoch: 20, loss: 0.8997376561164856, score: 0.7333333492279053
[Train] epoch: 30, loss: 0.8473371267318726, score: 0.6833333373069763
[Dev] epoch: 30, loss: 0.8396894931793213, score: 0.7333333492279053
[Train] epoch: 40, loss: 0.795616865158081, score: 0.7250000238418579
[Dev] epoch: 40, loss: 0.7904242873191833, score: 0.7333333492279053
[Train] epoch: 50, loss: 0.7523730397224426, score: 0.7416666746139526
[Dev] epoch: 50, loss: 0.7495757937431335, score: 0.7333333492279053
[Train] epoch: 60, loss: 0.715814471244812, score: 0.7833333611488342
[Dev] epoch: 60, loss: 0.715352475643158, score: 0.7333333492279053
best accuracy performence has been updated: 0.73333 --&gt; 0.80000
[Train] epoch: 70, loss: 0.6845521926879883, score: 0.8083333373069763
[Dev] epoch: 70, loss: 0.6863652467727661, score: 0.800000011920929
best accuracy performence has been updated: 0.80000 --&gt; 0.86667
[Train] epoch: 80, loss: 0.6575189232826233, score: 0.8166666626930237
[Dev] epoch: 80, loss: 0.6615443229675293, score: 0.8666666746139526
[Train] epoch: 90, loss: 0.6338950395584106, score: 0.8416666388511658
[Dev] epoch: 90, loss: 0.6400676369667053, score: 0.8666666746139526
[Train] epoch: 100, loss: 0.6130493879318237, score: 0.8416666388511658
[Dev] epoch: 100, loss: 0.6213017106056213, score: 0.8666666746139526
[Train] epoch: 110, loss: 0.5944927930831909, score: 0.8583333492279053
[Dev] epoch: 110, loss: 0.6047551035881042, score: 0.8666666746139526
[Train] epoch: 120, loss: 0.5778414011001587, score: 0.8500000238418579
[Dev] epoch: 120, loss: 0.5900436639785767, score: 0.8666666746139526
[Train] epoch: 130, loss: 0.5627920627593994, score: 0.8583333492279053
[Dev] epoch: 130, loss: 0.576863706111908, score: 0.8666666746139526
[Train] epoch: 140, loss: 0.5491021871566772, score: 0.8666666746139526
[Dev] epoch: 140, loss: 0.5649735331535339, score: 0.8666666746139526
[Train] epoch: 150, loss: 0.536577045917511, score: 0.875
[Dev] epoch: 150, loss: 0.5541784167289734, score: 0.8666666746139526
[Train] epoch: 160, loss: 0.5250566601753235, score: 0.8833333253860474
[Dev] epoch: 160, loss: 0.544320285320282, score: 0.8666666746139526
[Train] epoch: 170, loss: 0.5144104957580566, score: 0.8916666507720947
[Dev] epoch: 170, loss: 0.535270094871521, score: 0.8666666746139526
[Train] epoch: 180, loss: 0.5045303106307983, score: 0.8916666507720947
[Dev] epoch: 180, loss: 0.5269207954406738, score: 0.8666666746139526
[Train] epoch: 190, loss: 0.4953250288963318, score: 0.8916666507720947
[Dev] epoch: 190, loss: 0.5191838145256042, score: 0.8666666746139526
</code></pre><p>可视化观察训练集与验证集的准确率变化情况。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nndl <span class="keyword">import</span> plot</span><br><span class="line"></span><br><span class="line">plot(runner,fig_name=<span class="string">&#x27;linear-acc3.pdf&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>​<br><img src="/img-nndl/output_17_0.png" alt="png"><br>​    </p>
<h3 id="3-3-4-模型评价"><a href="#3-3-4-模型评价" class="headerlink" title="3.3.4 模型评价"></a>3.3.4 模型评价</h3><p>使用测试数据对在训练过程中保存的最佳模型进行评价，观察模型在测试集上的准确率情况。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载最优模型</span></span><br><span class="line">runner.load_model(<span class="string">&#x27;best_model.pdparams&#x27;</span>)</span><br><span class="line"><span class="comment"># 模型评价</span></span><br><span class="line">score, loss = runner.evaluate([X_test, y_test])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[Test] score/loss: &#123;:.4f&#125;/&#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(score, loss))</span><br></pre></td></tr></table></figure>
<pre><code>[Test] score/loss: 0.8000/0.6612
</code></pre><h3 id="3-3-5-模型预测"><a href="#3-3-5-模型预测" class="headerlink" title="3.3.5 模型预测"></a>3.3.5 模型预测</h3><p>使用保存好的模型，对测试集中的数据进行模型预测，并取出1条数据观察模型效果。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预测测试集数据</span></span><br><span class="line">logits = runner.predict(X_test)</span><br><span class="line"><span class="comment"># 观察其中一条样本的预测结果</span></span><br><span class="line">pred = paddle.argmax(logits[<span class="number">0</span>]).numpy()</span><br><span class="line"><span class="comment"># 获取该样本概率最大的类别</span></span><br><span class="line">label = y_test[<span class="number">0</span>].numpy()</span><br><span class="line"><span class="comment"># 输出真实类别与预测类别</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The true category is &#123;&#125; and the predicted category is &#123;&#125;&quot;</span>.<span class="built_in">format</span>(label[<span class="number">0</span>], pred[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>
<pre><code>The true category is 0 and the predicted category is 0
</code></pre><h2 id="3-4-小结"><a href="#3-4-小结" class="headerlink" title="3.4 小结"></a>3.4 小结</h2><p>本节实现了Logistic回归和Softmax回归两种基本的线性分类模型。</p>
<h2 id="3-5-实验拓展"><a href="#3-5-实验拓展" class="headerlink" title="3.5 实验拓展"></a>3.5 实验拓展</h2><p>为了加深对机器学习模型的理解，请自己动手完成以下实验：</p>
<ol>
<li>尝试调整学习率和训练轮数等超参数，观察是否能够得到更高的精度；</li>
<li>在解决多分类问题时，还有一个思路是将每个类别的求解问题拆分成一个二分类任务，通过判断是否属于该类别来判断最终结果。请分别尝试两种求解思路，观察哪种能够取得更好的结果；</li>
<li>尝试使用《神经网络与深度学习》中的其他模型进行鸢尾花识别任务，观察是否能够得到更高的精度。</li>
</ol>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2022/08/12/nndl/chapter4A/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">&lt;</strong>
      <div class="article-nav-title">
        
          第4章（上）：前馈神经网络理论解读
        
      </div>
    </a>
  
  
    <a href="/2022/08/12/nndl/chapter3A/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">第3章（上）：线性分类理论解读</div>
      <strong class="article-nav-caption">&gt;</strong>
    </a>
  
</nav>

  
</article>










    <section id="comments" style="margin:100px;padding:100px;background:rgb(64, 206, 241);">
      <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
      <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
      <script src="https://priesttomb.github.io/js/md5.min.js"></script>
      
      <div id="gitalk-container"></div>
      <script>
      var gitalk = new Gitalk({
          clientID: 'ecf230c60af3ed1123fa',
          clientSecret: '1e1daf2e6dd957a3f7d6b22b524387d14aafdb13',
          repo: 'hfut-zyw.github.io',
          owner: 'hfut-zyw',
          admin: ['hfut-zyw'],
          id: md5(location.pathname),      // Ensure uniqueness and length less than 50
          distractionFreeMode: false  // Facebook-like distraction free mode
        })
      gitalk.render('gitalk-container')
      </script>
      
    </section>

</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        <a href="https://space.bilibili.com/782159" target="_blank">访问我的哔哩哔哩</a> 
      </div>
        <div class="footer-right">
        &copy; 2022 LabmemNo.001
        </div>
    </div>
  </div>
</footer>
    </div>
    
  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">



<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: ,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>

<script src="/js/main.js"></script>




  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":170,"height":340},"mobile":{"show":false},"log":false});</script></body>
</html>